---
title: "Unit√† 2 Es"
author: "Lorenzo Demenia"
date: "2023-04-01"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduzione

In questa unit√† lavoreremo con variabili che possono essere :

1.  Continue : $f(x;\theta)$, quindi parleremo di caso continuo;
2.  Discrete : $P(X=x; \theta)$, quindi parleremo di caso discreto;

Per ognuna di esse c'√® bisogno di trovare lo stimatore attraverso due metodi :

1.  **Metodo dei Momenti:** in pratica dobbiamo trovare lo stimatore provando per ogni momento finch√© non troviamo lo stimatore
2.  **Metodo della Massima Verosimiglianza:** in questo caso invece ci servir√† analizzare i dati a nostra disposizione per trovare sempre lo stimatore

Incominciamo ad vedere come risolvere questi esercizi per tutti e due tipi di variabili che possiamo trovare in esame.

# 1) Ricerca Stimatore Variabili Continue

Sia $X_1,...,X_n$ un campione casuale semplice da una variabile casuale continua con funzione di densit√†: $$
f(x;\theta)=
\begin{cases} 
\frac{\theta}{x}(\frac{2}{x})^\theta \hspace{1cm} se\ x>2,\theta>1 \\
0 \hspace{1cm} altrimenti
\end{cases}
$$

1.  Si ottenga lo stimatore di $\theta$ con il metodo dei momenti
2.  Si ottenga lo stimatore di $\theta$ con il metodo della massima verosimiglianza
3.  Si verifichi la consistenza dei due stimatore ottenuti ai punti precedenti

## a) Metodo dei Momenti:

Per prima cosa dobbiamo cercare di risolvere la funzione :

$$
\mu_k(\theta^k) = M_k=\bar X^k
$$

Sapendo che $\mu(\theta)=E(\theta)$, allora prima di tutto dobbiamo vedere riusciamo a trovare un valore non nullo (cio√® $E(\theta)\not=0$), se dovessimo trovare che il primo momento non va bene, allora dobbiamo sostituire il $k$ con numero successivo fino a quando non troviamo un valore atteso diverso da zero. Adesso per√≤ risolviamolo per il primo momento: $$
\begin{align}
\mu_k(\theta)=E(\theta^1)=&\int^{+‚àû}_2 x*f(x;\theta)dx \\=&
\int^{+‚àû}_2 x*\frac{\theta}{x}(\frac{2}{x})^\theta dx \\&
semplifichiamo\ la\ x\ e\ invertiamo\ \theta \\=&
\int^{+‚àû}_2 \theta\ 2^\theta \ x^{-\theta} dx \\& porto\ fuori\ \theta \ 2^\theta \\=& 
\theta\ 2^\theta \int^{+‚àû}_2 x^{-\theta} dx \\&
ricordo: \int x^{-y} dx=\frac{x^{1-y}}{1-y} \\=&
\theta\ 2^\theta [\frac{x^{1-\theta}}{1-\theta}]^{+‚àû}_2 \\=&
\theta\ 2^\theta [\frac{x}{x^\theta(1-\theta)}]^{+‚àû}_2 \\=&
\theta\ 2^\theta [\frac{1}{x^{\theta-1}(1-\theta)}]^{+‚àû}_2 \\=&
\theta\ 2^\theta [\frac{1}{‚àû^{\theta-1}(1-\theta)}-\frac{1}{2^{\theta-1}(1-\theta)}] \\&
la\ prima\ frazione\ tende\ a\ 0\ invece\\&
la\ seconda\ si\ pu√≤\ riscrivere \\=&
\theta\ 2^\theta (-\frac{2^{1-\theta}}{1-\theta}) \\=&
- \frac{\theta 2 * 2}{2^\theta(1-\theta)} \\=&
- \frac{2\theta}{1-\theta}
\end{align}
$$ Siccome il primo momento ha funzionato allora ci possiamo fermare anche qui, ma nel caso in cui non dovesse andare bene si andr√† a ripetere l'operazione elevando alla seconda il valore interno al valore atteso, come abbiamo visto nella prima unit√†. Bene adesso dobbiamo solo controllare se $\mu_1=E(\theta^1)=- \frac{2\theta}{1-\theta}$ √® uguale ad $M_1=\bar X^1=\frac{1}{n}\sum^n_{i=1} X_i$, quindi alla **media campionaria**: $$
\begin{align}
-\frac{2\theta}{1-\theta}=\bar X \rightarrow& -\frac{2\theta}{1-\theta}=-\frac{1}{\bar X} \\ \rightarrow& \ 
\frac{1}{2\theta}-\frac{\theta}{2\theta}=-\frac{1}{\bar X} \\ \rightarrow& \
\frac{1}{2\theta}=\frac{1}{\bar X}+\frac{1}{2} \\\rightarrow& \
\frac{1}{2\theta}= \frac{-2+\bar X}{2\bar X}\\\rightarrow& \
2\theta=\frac{2\bar X}{\bar X-2}\\\rightarrow& \
\hat \theta = \frac{\bar X}{\bar X-2}
\end{align}
$$ A questo punto possiamo dire che, lo stimatore per il metodo dei momenti √® : $$
\hat \theta = \frac{\bar X}{\bar X-2}
$$

## b) Metodo della Verosimiglianza

Per trovare lo stimatore per il **metodo della verosimiglianza** si deve prima di tutto risolvere la funzione attraverso la formula predisposta, per√≤ siccome √® pi√π semplice, ci conviene usare la formula della **log-verosimiglianza**, piuttosto che quella della verosimiglianza , visto che gestire una somma di logaritmi √® pi√π semplice: $$
\begin{align}
l(\theta)=&\sum^n_{i=1} ln(\frac{\theta}{x_i}(\frac{2}{x_i})^\theta) \\=&
\sum^n_{i=1}[ln(\theta)-ln(x_i)+ln(2^\theta)-ln(x_i^\theta)] \\=&
\sum^n_{i=1}[ln(\theta)-ln(x_i)+2ln(\theta)-\theta ln(x_i)]\\&
siccome\ √®\ una\ costante\ togliamo\  -ln(x_i)  \\=&
\sum^n_{i=1}[3ln(\theta)+2ln(\theta)-\theta ln(x_i)] \\&
portiamo\ dentro\ la\ sommatoria \\=&
3ln(\theta)+2ln(\theta) \sum^n_{i=1} -\theta ln(x_i)
\end{align}
$$ bene adesso abbiamo trovato la log-verosimiglianza, quindi avendo la funzione: $$
l(\theta)=3ln(\theta)+2ln(\theta)-\theta \sum^n_{i=1} ln(x_i)
$$ possiamo trovare la **funzione punteggio**, che altro non √® che la derivata prima della **funzione della log-verosimiglianza** : $$
l'(\theta) = \frac{5}{\theta}+\sum^n_{i=1} ln(x_i)
$$ Ora sapendo la funzione punteggio, possiamo porla uguale a zero per trovare l'**equazione di verosimiglianza**: $$
\begin{align}
l'(\theta)=0 \rightarrow& \ \frac{5}{\theta}+\sum^n_{i=1} ln(x_i)=0\\&
sostituiamo\ la\ sommatoria\ con\ t  \\\rightarrow&\
\frac{5}{\theta}+t=0 \\\rightarrow&\
\frac{5}{\theta}=-t \\\rightarrow&\
\hat\theta=\frac{n}{t-n\ ln\ 2}
\end{align}
$$ dopo aver l'equazione di verosimiglianza, bisogna fare la derivata second di $l'(\theta)$ poich√© abbiamo bisogno di valutare il punto di massimo della funzione ricavata, dato che risolvendo l'equazione di verosimiglianza otteniamo il punto critico, ottenuto qui sopra, che corrisponde allo stimatore di massima verosimiglianza perch√© la derivata seconda della log-verosimiglianza √® negativa per qualsiasi valore di $\hat\theta$ : $$
l''(\theta)=- \frac{n}{\theta^2} <0
$$

## c) Consistenza:

Come abbiamo visto nella scorsa unit√† la consistenza viene valutata attraverso due metodi diversi:

1.  Attraverso la Legge dei Grandi numeri : cio√® se quello che abbiamo trovato rispetta la formula, visto nel primo modulo (non ho voglia di riscriverla üòÅ)
2.  Attraverso la Varianza : analizzando la varianza di uno dei due stimatori si pu√≤ vedere se √® consistente

In questo caso, lo stimatore di massima verosimiglianza di $\theta$ √®, consistente perch√© ci troviamo nelle condizioni di regolarit√† sotto le quali gli stimatori di massima verosimiglianza sono consistenti

# 2) Ricerca Stimatore Variabili Discrete

Sia $X_1,...,X_n$ un campione casuale semplice da una distribuzione discreta, con funzione di probabilit√† $$
P(X=x;\theta)=
\begin{cases}
\frac{\theta}{2} \hspace{1cm} se\ c=-1 \\
(1-\theta) \hspace{1cm} se\ x=0 \\
\frac{\theta}{2} \hspace{1cm} se\ x=1
\end{cases}
$$ In un campione di dimensione n=261 √® stato osservato : $$
109\ volte\ x=-1, \hspace{0.5cm} 49\ volte\ x=0, \hspace{0.5cm} 103\ volte\ x=1
$$ Bisogna trovare :

1.  Si ottenga lo stimatore di $\theta$ con il metodo dei momenti
2.  Si ottenga lo stimatore di $\theta$ con il metodo della massima verosimiglianza
3.  Si verifichi la consistenza dei due stimatore ottenuti ai punti precedenti

## a) Metodo dei Momenti

Come per le variabili continue, anche per le discrete bisogna trovare lo stimatore andando ad analizzare ogni momento finch√© non abbiamo un valore diverso da zero. Incominciamo con il primo momento e vediamo se ci va bene:

### Momento 1 :

$$
\begin{align}
\mu_1=E(\bar X^1)=& (-1)(\frac{\theta}{2})+(0)(1-\theta)+(1)(\frac{\theta}{2}) \\=&
-\frac{\theta}{2}+\frac{\theta}{2} \\=&
\ 0
\end{align}
$$

Siccome il momento uno ha dato come risultato 0 allora non possiamo usarlo, quindi dobbiamo calcolarlo per il secondo momento .

### Momento 2 :

$$
\begin{align}
\mu_2=E(\bar X^2)=& (-1)^2(\frac{\theta}{2})+(0)^2(1-\theta)+(1)^2(\frac{\theta}{2}) \\=&
\frac{\theta}{2}+\frac{\theta}{2} \\=&
\ \theta
\end{align}
$$

siccome il secondo momento ci ha tornato un valore diverso da zero, allora lo possiamo usare.

Bene adesso ci manca solo di analizzare la media campionaria del secondo momento con il risultato trovato qui sopra, in questo modo possiamo trovare lo stimatore $\hat\theta$:

$$
\begin{align}
\mu_2= \bar X^2 \rightarrow&\ \hat\theta = \frac{1}{n}\sum^n_{i=1} X_i^2 \\\rightarrow&\
\hat\theta = \frac{(109+103)}{261}=0.81
\end{align}
$$

## b) Metodo della Verosimiglianza

Come per le variabili continue, anche per le discrete ci conviene usare il metodo della **log-verosimiglianza** poich√© √® pi√π semplice da calcolare rispetto alla **verosimiglianza**

$$
\begin{align}
l(\theta)=& \sum^n_{i=1} \ln(\theta) \\=&
\sum^n_{i=1} \ln((\frac{\theta}{2})^{109}*(1-\theta)^{49}*(\frac{\theta}{2})^{103}) \\=&
\sum^n_{i=1}[109\ln(\theta)-109\ln(2)+49\ln(1-\theta)+103\ln(\theta)-103\ln(2)] \\&
siccome\ 109\ln(2)\ e\ 103\ln(2)\ sono\ costanti\ le\ possiamo\ togliere \\=&
109n\ln(\theta)+49n\ln(1-\theta)+103n\ln(\theta) \\=&
(109+103)n\ln(\theta)+49n\ln(\theta) \\=&
212\ln(\theta)+49\ln(\theta)
\end{align}
$$

Bene ora conoscendo la **log-verosimiglianza** possiamo calcolare la **funzione punteggio** :$$
\begin{align}
l'(\theta)=\frac{212}{\theta}-\frac{49}{1-\theta}
\end{align}
$$

ora poniamola uguale a zero e vediamo di trovare l'**equazione di verosimiglianza :**

$$
\begin{align}
l'(\theta)=0 \rightarrow&\ \frac{212}{\theta}-\frac{49}{1-\theta}=0 \\\rightarrow&\
\frac{212}{\theta}=\frac{49}{1-\theta} \\\rightarrow&\
\frac{\theta}{212}=\frac{1-\theta}{49} \\\rightarrow&\
\frac{1-\theta}{\theta}=\frac{49}{212} \\\rightarrow&\
\frac{1}{\theta}-\frac{\theta}{\theta}= \frac{49}{212} \\\rightarrow&\
\frac{1}{\theta}=\frac{49}{212}+1 \\\rightarrow&\
\frac{1}{\theta} = \frac{49+212}{212} \\\rightarrow&\
\ \hat\theta = \frac{261}{212} = 0.81
\end{align}
$$

Una volta trovata la funzione di verosimiglianza, dobbiamo trovare la derivata seconda :

$$
\begin{align}
l''(\theta)= -\frac{212}{\theta^2}-\frac{49}{(1-\theta)^2}
\end{align}
$$

una volta trovata la derivata seconda bisogno porla minore di zero e vedere come si comporta :

$$
\begin{align}
l''(\theta)<0 \rightarrow&\ -\frac{212}{\theta^2}-\frac{49}{(1-\theta)^2} < 0
\end{align}
$$

poich√© sappiamo che $\hat\theta =0$, sostituendo si ottiene : $-1711.549<0$

Fortunatamente in questo caso i due metodi sono uguali, ora dobbiamo solo vedere l'informazione osservata calcolata in $\hat\theta$ , per trovare l'**errore standard**:

$$
\begin{align}
J(\hat\theta)=& -\frac{212}{\theta^2}-\frac{49}{(1-\theta)^2} \\&
sostituiamo\ \hat\theta\ con\ il\ valore\ trovato\ 0.81 \\=&
-\frac{212}{0.81^2}-\frac{49}{(1-0.81)^2} \\=&
\ 1680.46
\end{align}
$$

quindi, una stima dell'errore standard di $\hat\theta$ √® $1/\sqrt{1680.46}=0.024$.
