---
title: "Unità 4"
author: "Lorenzo Demenia"
date: "2023-09-04"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
```

# Anlisi preliminare
Nella verifica delle ipotesi vengono confrontate due ipotesi, dette anche **sistema di ipotesi**:

1. $H_0$ **ipotesi nulla**: rappresenta lo stato delle cose, ciò in cui si crede finché i dati non forniscono una **chiara evidenza** contraria
2. $H_A$ **ipotesi alternativa**: che è l'opposto dell'ipotesi nulla 

In questa fase bisogna capire che tipo di **ipotesi** vogliamo usare: 

- Ipotesi **alternativa bilaterale(test a due code)**: in pratica controllo se l'ipotesi alternativa
è diversa dell'ipotesi nulla 

$$
H_0: \theta = \theta_0 \hspace{0.5cm} contro \hspace{0.5cm} H_A:  \theta \not = \theta_0
$$

- Ipotesi **unilaterale sinistro (test ad una coda)**: controllo se se l'ipotesi nulla è migliore dell'altrernativa

$$
    H_0: \theta \ge \theta_0 \hspace{0.5cm} contro \hspace{0.5cm} H_A:  \theta < \theta_0
$$

- Ipotesi **unilatrale destra (test ad una coda)**: controllo se l'ipotesi nulla è peggiore dell'ipotesi alternativa

$$
    H_0: \theta \le \theta_0 \hspace{0.5cm} contro \hspace{0.5cm} H_A:  \theta > \theta_0
$$

Nei test ad una coda, se rifiutiamo $H_0$ quando $\theta = \theta_0$ allora rifiutiamo $H_0$ per tutti gli altri valori. 
Quindi, anziché scrivere $H_0: \theta \ge \theta_0$ o $H_0: \theta \le \theta_0$ possiamo scrivere $H_0: \theta = \theta_0$

## Errori 

Si parla di errore quando andiamo a formulare conclusioni sbagliate a causa dell'**errore campionario**, le situazioni 
che possiamo incontrare sono :

![]("/var/folders/zc/3mbjvbdd27ldx89g1mdhf3rw0000gn/T/TemporaryItems/NSIRD_screencaptureui_omlKi2/Screenshot 2023-06-09 alle 15.54.59.png")

- **Errore del I tipo**: rifiutare $H_0$ quando è vera, molto più grave del secondo, di solito si fissa un valore massimo per la sua probabilità
- **Errore del II tipo**: non rifiutare $H_0$ quando è falsa 

### Livello di Significatività: 

Il livello di un test è la probabilità di commettere un errore del **I tipo**:
$$
\alpha = Pr(Rifiutare \space H_0 \space quando \space H_0 \space è \space vera)
$$
La probabilità di rifiutre $H_0$ quando è falsa è detta **potenza del test**:
$$
\beta(\theta) = Pr(Rifiutare \space H_0 \space quando \space H_A \space è \space vera)
$$

# 1) Test Z 
Per risolvere questi tipi di esercizi, che tante volte vengono accompagnati ad un calcolo 
della statistica, che in questo caso ci siamo accorti che è una **statista Z**, bisogna tenere
in considerazione diversi aspetti, adesso con un esempio ve li illustro: 

Supponiamo di avere uno stimatore $\hat \theta$ **non distorto e normale**, se l'ipotesi nulla 
è $H_0 = \theta_0$ allora è naturale considereare la **statistica Z** come statistica test: 

$$
    Z= \frac{\hat\theta -\theta_0}{SE(\hat\theta)}
$$

Se i valori della statistica Z sono: 

- **vicini allo zero**: indicherenno che l'evidenza empirica non permette di rifiutre $H_0$
- **distanti dallo zero**: indicherenno con evidenza empirica contro $H_0$

In questo caso dobbiamo capire che tipo di test dobbiamo attuare, 
siccome esistono due tipi di test, a seconda dell'**ipotesi alternativa**:

1. Test a una coda
2. Test a due code 

## 1.1) Test Z a una coda 

Nel test ad una coda abbiamo visto che esistono di due tipi: 

1. **Unilaterale Destro**: controllo se l'ipotesi nulla è peggiore dell'ipotesi alternativa
    $$
         H_0: \theta = \theta_0 \hspace{0.5cm} contro \hspace{0.5cm} H_A:  \theta > \theta_0
    $$
    
    In questo caso si rifiuta per **valori troppo grandi** della statistica Z

    $$
        R = [z_{\alpha}, +∞ ) \hspace{0.5cm} e \hspace{0.5cm} A = (-∞ , z_{\alpha})
    $$

    E il livello di significatività è 
    $$
        Pr(Errore \space I \space tipo) = Pr(Z \in R|H_0) = Pr(Z>z_{\alpha})= \alpha
    $$

2. **Unilaterale Sinistro**: controllo se se l'ipotesi nulla è migliore dell'altrernativa
    $$
         H_0: \theta = \theta_0 \hspace{0.5cm} contro \hspace{0.5cm} H_A:  \theta < \theta_0
    $$
    
    In questo caso si rifiuta per **valori troppo piccoli** della statistica Z

    $$
        R = (-∞, -z_{\alpha}] \hspace{0.5cm} e \hspace{0.5cm} A = (-z_{\alpha}, +∞)
    $$

    E il livello di significatività è 
    $$
        Pr(Errore \space I \space tipo) = Pr(Z \in R|H_0) = Pr(Z<-z_{\alpha})= \alpha
    $$

$H_0 = \theta_0$ e non $H_0 \le \theta_0$, oppure $H_0 \ge \theta_0$ siccome come ho detto prima 
quando abbiamo maggiore o minore uguale possiamo mettere direttamente uguale 

## 1.2) Test Z a due code 

Se l'altrernativa è **bilaterale**: 
    $$
        H_0: \theta = \theta_0 \hspace{0.5cm} contro \hspace{0.5cm} H_A:  \theta \not = \theta_0
    $$

Si rifiuta per **valori sia troppo piccoli che troppo grandi** della statista Z: 
    $$
        R = (-∞, -z_{\alpha/2}] \cup [z_{\alpha/2}, +∞) \hspace{0.5cm} e \hspace{0.5cm} A = (-z_{\alpha/2}, z_{\alpha/2})
    $$
E il livello di significatività è: 
    $$
        \begin{align}
        Pr(Errore \space I \space tipo) =& Pr(Z \in R|H_0) \\
                                        =& Pr(Z<-z_{\alpha/2})+ Pr(Z>z_{\alpha/2}) \\
                                        =& \frac{\alpha}{2}+\frac{\alpha}{2} \\
                                        =& \alpha
        \end{align}
    $$

## 1.3) Massima Verosimiglianza del Test Z

Se l'ipotesi nulla $H_0: \theta=\theta_0$ è vera, sotto assunzioni di regolarità, los timatore di massima 
verosimiglianza ha distribuzione approssimativamente normale, possiamo usare questo risultato per cotruire le statistiche
test Z: 

$$
    Z = I(\theta_0)^{1/2}(\hat\theta- \theta_0) \hspace{0.5cm} oppure \hspace{0.5cm} Z= J(\theta_0)^{1/2}(\hat\theta- \theta_0)
$$

Alternativamente, usando l'errore standard stimato 

$$
    Z = I(\hat\theta)^{1/2}(\hat\theta- \theta_0) \hspace{0.5cm} oppure \hspace{0.5cm} Z= J(\hat\theta)^{1/2}(\hat\theta- \theta_0)
$$

Infatti, se l'ipotesi null è vera allora 
$\hat\theta \rightarrow \theta_0$, per $n$ sufficientemente grande

# 2) Test T 

Anche qui distingueremo in due tipi di test differenti, prendendo un campione di piccole dimensionei 
da una popolazione normale con media $\mu$ e varianza $\sigma^2$ **entrambe ignote**, con una valutazione dell'
ipotesi $H_0: \mu =\mu_0$: 

1. **Test a due code**: come prima dove prendiamo in esame solo $H_A : \mu \not = \mu_0$
2. **Test ad una code**: come prima prendiamo in esame, 
    - $H_A : \mu > \mu_0$
    - $H_A : \mu < \mu_0$

Per valutare le ipotesi utilizzeremo la statistica T di Student, $n-1$ gradi di libertà:

$$
    T = \frac{\sqrt{n}(\bar X - \mu_0)}{S}
$$

## 2.1) Test T a una coda: 

Nel test ad una coda abbiamo visto che esistono di due tipi: 

1. **Unilaterale Destro**: controllo se l'ipotesi nulla è peggiore dell'ipotesi alternativa
    $$
         H_0: \theta = \theta_0 \hspace{0.5cm} contro \hspace{0.5cm} H_A:  \theta > \theta_0
    $$
    
    In questo caso si rifiuta per **valori troppo grandi** della statistica T

    $$
        R = [t_{\alpha}, +∞ ) \hspace{0.5cm} e \hspace{0.5cm} A = (-∞ , t_{\alpha})
    $$

    E il livello di significatività è 
    $$
        Pr(Errore \space I \space tipo) = Pr(T \in R|H_0) = Pr(T>t_{\alpha})= \alpha
    $$

2. **Unilaterale Sinistro**: controllo se se l'ipotesi nulla è migliore dell'altrernativa
    $$
         H_0: \theta = \theta_0 \hspace{0.5cm} contro \hspace{0.5cm} H_A:  \theta < \theta_0
    $$
    
    In questo caso si rifiuta per **valori troppo piccoli** della statistica Z

    $$
        R = (-∞, -t_{\alpha}] \hspace{0.5cm} e \hspace{0.5cm} A = (-t_{\alpha}, +∞)
    $$

    E il livello di significatività è 
    $$
        Pr(Errore \space I \space tipo) = Pr(T \in R|H_0) = Pr(T<-t_{\alpha})= \alpha
    $$

## 2.2) Test T a due code: 

Se l'altrernativa è **bilaterale**: 
    $$
        H_0: \theta = \theta_0 \hspace{0.5cm} contro \hspace{0.5cm} H_A:  \theta \not = \theta_0
    $$

Si rifiuta per **valori sia troppo piccoli che troppo grandi** della statista T: 
    $$
        R = (-∞, -t_{\alpha/2}] \cup [t_{\alpha/2}, +∞) \hspace{0.5cm} e \hspace{0.5cm} A = (-t_{\alpha/2}, t_{\alpha/2})
    $$
E il livello di significatività è: 
    $$
        \begin{align}
        Pr(Errore \space I \space tipo) =& Pr(T \in R|H_0) \\
                                        =& Pr(T<-t_{\alpha/2})+ Pr(T>t_{\alpha/2}) \\
                                        =& \frac{\alpha}{2}+\frac{\alpha}{2} \\
                                        =& \alpha
        \end{align}
    $$

## 2.3) Test T a due campioni: 

In questo caso consideriamo di confrontare delle medie di due **popolazioni normali** con **varianze ignote**.

In pratica andiamo a controllare se l'ipotesi nulla $H_0: \mu_X -\mu_Y=D$ con tutte e tre le alternative viste per il tipo di test, spesso si assume $D=0$, per cui 
$H_0: \mu_x=\mu_y$: 
$$
    H_A: \mu_x \not= \mu_x\hspace{0.5cm} o \hspace{0.5cm} H_A: \mu_x > \mu_x\hspace{0.5cm} \hspace{0.5cm} o \hspace{0.5cm} H_A: \mu_x > \mu_x \hspace{0.5cm}
$$

Nel caso di intervalli di confidenza dobbiamo distinguere fra due casi: 

1. **Varianze uguali**: $\sigma^2_X= \sigma^2_Y$
2. **Varianze diverse**: $\sigma^2_X \not= \sigma^2_Y$

### 2.3.1) Test T a due campioni con Varianze Uguali: 

In questo caso si usa la statistica T in questo modo: 
$$
    T= \frac{\bar X - \bar Y - D}{S_p \sqrt{\frac{1}{n}+\frac{1}{m}}}
$$

dove $S^2_p$ indica la viarianza "pooled" che abbiamo già incontrato nel calcolo degli intervalli di confidenza

$$
S^2_p = \frac{(n-1)S^2_X + (m-1)S^2_Y}{n+m-2}
$$

La statistica T si distribuisce come una variabile casuale $T$ di Student con $n+m-2$ gradi di libertà sotto 
$H_0$

### 2.3.2) Test T a due campioni con Varianze Diverse: 

In questo caso si usa la statistica T in questo modo: 
$$
    T= \frac{\bar X - \bar Y - D}{\sqrt{\frac{S^2_X}{n}+\frac{S^2_Y}{m}}}
$$

La statistica $T$ *non* si distribuisce **esattamente** come una variabile casuale $T$ di
Student sotto $H_0$ (approssimazione di *Satterthwaite*), si approsima con $\nu$ : 
$$
    \nu = \frac{\frac{S^2_X}{n}+ \frac{S^2}{m}}{\frac{S^4_X}{n^2(n-1)}+\frac{S^4_Y}{m^2(m-1)}}
$$

# 3) Fissare il livello di Significatività di $\alpha$

I test con livello di significatività fissata che abbiamo visto fin ora ci portano solo 
a rifiutare o meno, ma non "misurano" l'evidenza a favore o contro l'ipotesi nulla.

In questo caso possiamo usare due approcci diversi di apporccio alla verifica, basato sul **Livello di Significatività osservato**.

Evita di fissare un livello di significatività in modo miusare l'ammontare di evidenza a favore delle ipotesi.

Viene definito come *la probabilità di ottenere un valore della statista test uguale o più estremo di quello osservatos se l'ipotesi nulla fosse vera* 
si distiunge in due tipi: 

1. Livello osservato **Grande**: vuol dire che quello che abbiamo osservato non era poi così estremo e quindi **non** possiamo **rifiutare $H_0$**
2. Livello osservato **Piccolo**: vuol dire che abbiamo osservato davvero l'estremo e quindi **rifiutiamo $H_0$**

## 3.1) Calcolo del livello di Significatività Osservato

Il calcolo dipende da $H_A$ e dalla statista test, quello che vedremo quì sotto vale lo stesso principio sia per la 
statitica $Z$ che quella $T$. 

Come detto prima, dobbiamo distinguere i tre casi di ipotesi alternativa: 

1. **Unilaterale Destra** ($H_A: \theta > \theta_0$): in questo caso si rifiuta $H_0$ per valori **Troppo grandi**,
                                                    quindi il livello di significatività osservato è la probabilità di osservare 
                                                    qualcosa tanto o più estremo di $z$, ovvero: 
                                                    $$
                                                        p= Pr(Z \ge z) = 1- \Phi(z)
                                                    $$
2. **Unilaterale Sinistra** ($H_A: \theta < \theta_0$): si rifiuta $H_0$ per valori **Troppo Piccoli** e il livello di significatività
                                                        osservato è pari a: 
                                                        $$
                                                            p= Pr(Z \le z) = \Phi(z)
                                                        $$
3. **Bilaterale** ($H_A: \theta \not= \theta_0$): si rifiuta $H_0$ sia per valori **Troppo Grandi** che per valori **Troppo Piccoli**,
                                                in questo caso il livello di significatività osservato è: 
                                                $$
                                                    p= Pr(Z > |z|)+ Pr(Z<-|z|) = 2\{1-\Phi(|z|) \}
                                                $$
